# ColorBayes Bayesian color constancy


We aim to correct the local colour distortion on plant phenotyping images caused by non-uniform illumination. The corrected image will show the colours of individual plants as if they were taken under the same standard illuminant (D65). This colour constancy approach has two main steps. The first step is to estimate an unknown illuminant's colour and spatial distribution that causes the local colour distortion. For this step, it is required a training dataset (ground truth), and observed image data. Also, it is used the Bayes' rule and the maximum a posteriori (MAP). The second step is transforming the observed image using the chromaticity adaptation method.


<figure>
  <img src="https://github.com/diloc/Color_correction/blob/main/images/Figure_2_ColorLight_distribution4.png">
  <figcaption>
  Figure 1 Light environment characteristics in the HTPP system. (a) A top-view image capturing one hundred and forty-eight pots and twelve Macbeth ColorCheckers, illustrating non-uniform illumination. (b) Spatial distribution of the illumination colour on the plant phenotyping scene. (c) Illumination colour distribution on the Chromaticity diagram using the 1931 CIE colourimetric system coordinates. (d) Spectral Irradiance at (x = 20 cm and y = 20 cm) and (x = 0 cm and y = 6 cm), the wavelength range is from 325 nm to 785 nm on the horizontal axis and the spectral irradiance [Î¼W cm-2 nm-1] on the vertical axis. Two peaks represent the primary emission LED lights at blue (450 nm) and red (630 nm), and a curve plateau between these peaks (550 - 600 nm).
  </figcaption>
</figure>

## Description

Our method relies on the following assumptions:
1. An observed image (5105 x 3075 pixels) comprises three independent colour channels (ğ‘ = ğ‘…, ğº, ğµ).
2. The reflectance $ğ‘Ÿ_ğ‘ğ‘—$ is a random variable at the location ğ‘— = 0,1,2, â€¦,ğ‘š, and colour channel c. Two adjacent reflectances are independent of each other, and the joint probability is given by $ğ‘(ğ‘Ÿ_{ğ‘ğ‘—}, ğ‘Ÿ_{ğ‘ğ‘™}) = ğ‘(ğ‘Ÿ_{ğ‘ğ‘—})ğ‘(ğ‘Ÿ_{ğ‘ğ‘™})$. Based on the same assumption, all reflectance are independent events with joint probability $$p(R_{c}) = \prod_{j=1}^{m} ğ‘(ğ‘Ÿ_{ğ‘ğ‘—})$$.
3. The illuminant ğ‘™ğ‘ğ‘— is also a random variable at the location ğ‘— = 0,1,2, â€¦, ğ‘›, and colour channel c.
4. The illumination and the reflectance are statistically independent of each other $ğ‘(ğ¿_{ğ‘ğ‘—}, ğ‘…_{ğ‘ğ‘—}) = ğ‘(ğ¿_{ğ‘ğ‘—})ğ‘(ğ‘…_{ğ‘ğ‘—})$.
5. An image is divided into an m number of small images corresponding to individual pot areas ğ´ğ‘ where the index ğ‘ = 0,1,2, â€¦, ğ‘š indicates the number of pot areas. It means that each pot area ğ´ğ‘ has a predetermined n number of pixels $ğ‘_{ğ‘ğ‘} = \{ ğ‘§_{ğ‘ğ‘â„} \}$ at the location â„ = 0,1,2, â€¦, ğ‘. Also, the reflectance $ğ‘…_{ğ‘ğ‘} = {ğ‘Ÿğ‘ğ‘â„}$ and illuminant $ğ¿_{ğ‘ğ‘} = \{ ğ‘™_{ğ‘ğ‘â„}\}$ associated with each pixel within a pot area share the same location â„.
6. The illuminant is constant for all pixels within a pot area $ğ´_ğ‘$, meaning, $ğ‘™_{ğ‘ğ‘} = ğ‘™_{ğ‘ğ‘â„}$ and ğ¿ğ‘ğ‘ = {ğ‘™ğ‘ğ‘}. Then, the probability distribution of the illuminant is uniform, $ğ‘(ğ‘™_{ğ‘ğ‘}) = ğ‘¢_{ğ‘ğ‘}$, where $ğ‘¢_{ğ‘ğ‘}$ is a constant value. However, two adjacent pot area illuminants are independent of each other $ğ‘(ğ‘™_{ğ‘ğ‘}, ğ‘™_{ğ‘ğ‘}) = ğ‘(ğ‘™_{ğ‘ğ‘})ğ‘(ğ‘™_{ğ‘q})$.

### Likelihood: 
The likelihood of the pixel class is given the illuminant and reflectance and follows a normal distribution. <br/>
$$p(z_{cki}â”‚l_{cki},r_{cki})= \frac{1}{\sqrt{2\pi \sigma_{ck}^2}}  expâ¡\biggl(-\frac{(z_{cki}-l_{ck}r_{cki})^2}{2\sigma_{ck}^2}\biggr)$$  


### Priors: Reflectance & Illuminant: 
We created an **image dataset** to get the reflectance and illuminant prior distributions. It has images of green fabric pieces on pots and Macbeth colorChecker charts. They were illuminated using D65 standard illuminant.. <br/>

$$P(r_{cki})= \frac{1}{\sqrt{2\pi \tau_{ck}^2}}  expâ¡\biggl(-\frac{(r_i-\mu_{ck})^2}{2\tau_{ck}^2}\biggr)$$ <br/>

As the illumination is uniform over a pixel class, the probability distribution is given by:
$$p(l_{ck})=u_{ck}$$ <br/>

### Posterior
It is possible to analytically calculate the posterior distribution using the Bayes' rule as the prior is a conjugate prior for the likelihood function. The posterior distribution is given by:
$$P(L_{ck}|Z_{ck})=\prod_{i=1}^{n} \int \frac{p(z_{cki}|l_{lck}, r_{cki})p(z_{cki}) pl(l_{ck})}  {p(z_{cki})} dr_{cki} $$ <br/>


### Maximum a posteriori 
We estimate the illumination value when the posterior distribution reaches the highest value.

$$  \hat{l}_{MAP} =\underset{l_{ck}}{\operatorname{argmax}}  P(L_{ck}|Z_{ck})$$

## Resources


* Source Repository (prior): https://github.com/diloc/Color_correction/blob/8dea8b92ac3cea5e5c198348c04a50d10c2f8adb/Color_Constancy/prior.ipynb
* Source Repository (main): https://github.com/diloc/Color_correction/blob/919477408e1679f0c3c715a99ab9bff2afca433f/Color_Constancy/main.ipynb

## Dependencies
* Python (3. 7 or higher).
* Pandas (1.0.3 or higher).
* OpenCV (4.2.0 or higher).
* Datetime
* Scipy (1.4.1 or higher).
* Matplotlib (1.18.1 or higher).



# Results
The ColorBayes algorithm improved the accuracy of plant color on images taken by an indoor plant phenotyping system. Compared with existing approaches, it gave the most accurate metric results when correcting images from a dataset of Arabidopsis thaliana images.




